#!/usr/bin/env python3
"""
aws_redshift_inspect_user: Inspect usage and ownership details for a given Redshift user,
plus additional data like role memberships, active sessions, stored procs, etc.

Example usage:
  ./aws_redshift_inspect_user \
    --conn redshift://admin@my-cluster.us-east-1.redshift.amazonaws.com:5439 \
    --databases dev,prod \
    --target-user old_employee
"""

import argparse
import getpass
import psycopg2
import urllib.parse
import sys
import json

def parse_connection_uri(conn_uri: str):
    parsed = urllib.parse.urlparse(conn_uri)
    params = {
        'host': parsed.hostname,
        'port': parsed.port or 5439, 
        'database': 'error_no_database',
        'user': parsed.username,
    }
    return params

def inspect_objects_owned_by(cursor, target_user: str):
    """
    Show database objects owned by the target_user (tables, views, etc.).
    """
    query = """
    SELECT n.nspname AS schema_name,
           c.relname AS object_name,
           CASE c.relkind
                WHEN 'r' THEN 'table'
                WHEN 'v' THEN 'view'
                WHEN 'i' THEN 'index'
                WHEN 'S' THEN 'sequence'
                WHEN 't' THEN 'TOAST table'
                WHEN 'm' THEN 'materialized view'
                ELSE c.relkind::text
           END as object_type
    FROM pg_class c
    JOIN pg_namespace n ON n.oid = c.relnamespace
    JOIN pg_user u ON u.usesysid = c.relowner
    WHERE u.usename = %s
      AND n.nspname NOT IN ('pg_catalog','information_schema','pg_internal')
      AND c.relkind NOT IN ('','c')
    ORDER BY schema_name, object_name;
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def inspect_login_events(cursor, target_user: str, limit=5000):
    """
    Show recent connection attempts by the target_user from stl_connection_log.
    """
    query = f"""
    SELECT
       username,
       event,
       remotehost,
       recordtime AS start_time,
       duration
    FROM stl_connection_log
    WHERE username = %s
    ORDER BY recordtime DESC
    LIMIT {limit};
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def inspect_recent_queries(cursor, target_user: str, limit=50):
    """
    Show recent queries run by the target user from stl_query.
    """
    query = f"""
    SELECT
        query,
        querytxt,
        starttime,
        endtime
    FROM stl_query
    WHERE userid = (
      SELECT usesysid
      FROM pg_user
      WHERE usename = %s
    )
    ORDER BY starttime DESC
    LIMIT {limit};
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def inspect_group_membership(cursor, target_user: str):
    """
    List the groups/roles the user is a member of.
    Redshift uses 'pg_group' similarly to Postgres, but the approach may differ by version.
    """
    # One possible approach: pg_group.grolist is an array of usesysid values.
    # We join with pg_user to see which groups the user belongs to.
    query = """
    SELECT g.groname
    FROM pg_group g
    JOIN pg_user u ON u.usesysid = ANY(g.grolist)
    WHERE u.usename = %s
    ORDER BY g.groname;
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def inspect_active_sessions(cursor, target_user: str):
    """
    Check stv_sessions to see if the user currently has an active session.
    """
    query = """
    SELECT 
        process,
        user_name,
        db_name,
        starttime,
        timeout_sec
    FROM stv_sessions
    WHERE user_name = %s
    ORDER BY starttime DESC;
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def inspect_stored_procs(cursor, target_user: str):
    """
    List stored procedures owned by the user. Redshift has 'svv_procedures' or
    'information_schema.routines', but usage differs by version/permissions.
    """
    # Attempt a query using svv_procedures (available in Redshift).
    # If your Redshift version doesnâ€™t have it, adapt accordingly.
    query = """
    SELECT
            p.identity_name,
            p.function_name,
            r.schema_name,
            function_type,
            p.privilege_type,
            admin_option
    FROM svv_redshift_functions r
    JOIN svv_function_privileges p ON r.function_name = p.function_name
    WHERE p.identity_name = %s
    ORDER BY r.database_name, r.function_name;
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def inspect_other_logs(cursor, target_user: str, limit=1000):
    """
    Dump any additional log data for the user from (for example) stl_querytext,
    stl_error, or stl_ddltext. We'll do a generic approach:
    - This is just an example. Adapt or expand as needed.
    """
    # Example: stl_error to find errors thrown by that user.
    query = f"""
    SELECT userid,
           recordtime,
           errcode,
           e.process,
           trim(e.file) as filename,
           trim(e.pid) as session_id,
           e.linenum,
           trim(e.error) as err_reason
    FROM stl_error e
    WHERE userid = (
      SELECT usesysid
      FROM pg_user
      WHERE usename = %s
    )
    ORDER BY recordtime DESC
    LIMIT {limit};
    """
    cursor.execute(query, (target_user,))
    rows = cursor.fetchall()
    return rows

def main():
    parser = argparse.ArgumentParser(
        description="Inspect usage and ownership details for a given Redshift user."
    )
    parser.add_argument(
        "--conn",
        required=True,
        help="Redshift connection URI (password will be prompted).  This does NOT use the database part of the URL, even if present.  See the --databases option for that."
    )
    parser.add_argument(
        "--databases",
        required=False,
        help="OPTIONAL: Comma-separated list of databases to inspect.  If not specified, all databases will be inspected (this introspection requires that user is allowed to connect to 'dev' database)."
    )
    parser.add_argument(
        "--target-user",
        required=True,
        help="Which Redshift user do you want to inspect?",
    )
    parser.add_argument(
        "--json-out",
        default=None,
        help="If specified, write the collected data in JSON format to this file."
    )
    args = parser.parse_args()

    # Parse the connection parameters (minus password)
    conn_params = parse_connection_uri(args.conn)
    user_for_prompt = conn_params["user"]
    if not user_for_prompt:
        print("Error: The connection URI must include a username.")
        sys.exit(1)

    pw = getpass.getpass(prompt=f"Password for '{user_for_prompt}': ")

    # If databases is not specified, connect and get a list of all databases
    if not args.databases:
        try:
            conn = psycopg2.connect(
                host=conn_params["host"],
                port=conn_params["port"],
                dbname="dev",
                user=conn_params["user"],
                password=pw,
            )
            conn.autocommit = True
        except Exception as e:
            print(f"Failed to connect to Redshift database 'postgres': {e}")
            sys.exit(1)

        with conn.cursor() as cur:
            cur.execute("SELECT datname FROM pg_database WHERE datname NOT IN ('template0', 'template1');")
            rows = cur.fetchall()
            databases = [row[0] for row in rows]

        conn.close()
    else:
        databases = args.databases.split(',')

    data_report = {}
    for db in databases:
        conn_params["database"] = db.strip()
        try:
            conn = psycopg2.connect(
                host=conn_params["host"],
                port=conn_params["port"],
                dbname=conn_params["database"],
                user=conn_params["user"],
                password=pw,
            )
            conn.autocommit = True
        except Exception as e:
            print(f"Failed to connect to Redshift database '{conn_params['database']}': {e}")
            continue

        with conn.cursor() as cur:
            print(f"\nConnected to database '{conn_params['database']}'. Inspecting user '{args.target_user}'...\n")

            # Initialize database-specific report
            db_report = {}

            # 1) Objects owned by the user
            owned_objects = inspect_objects_owned_by(cur, args.target_user)
            db_report["owned_objects"] = [
                {
                    "schema": row[0],
                    "object_name": row[1],
                    "object_type": row[2]
                }
                for row in owned_objects
            ]

            # 2) Group memberships
            group_memberships = inspect_group_membership(cur, args.target_user)
            db_report["group_memberships"] = [row[0] for row in group_memberships]

            # 3) Active sessions
            active_sessions = inspect_active_sessions(cur, args.target_user)
            db_report["active_sessions"] = []
            for row in active_sessions:
                db_report["active_sessions"].append({
                    "process": row[0],
                    "user_name": row[1],
                    "db_name": row[2],
                    "start_time": str(row[3]),
                    "query": row[4]
                })

            # 4) Stored procedures owned by the user
            stored_procs = inspect_stored_procs(cur, args.target_user)
            db_report["stored_procedures"] = []
            for row in stored_procs:
                db_report["stored_procedures"].append({
                    "identity_name": row[0],
                    "function_name": row[1],
                    "schema_name": row[2],
                    "function_type": row[3],
                    "privilege_type": row[4],
                    "admin_option": row[5]
                })

            # 5) Recent login events
            login_events = inspect_login_events(cur, args.target_user)
            db_report["login_events"] = []
            for row in login_events:
                db_report["login_events"].append({
                    "username": row[0],
                    "event": row[1],
                    "remotehost": row[2],
                    "start_time": str(row[3]),
                    "duration": row[4]
                })

            # 6) Recent queries
            recent_queries = inspect_recent_queries(cur, args.target_user)
            db_report["recent_queries"] = []
            for row in recent_queries:
                db_report["recent_queries"].append({
                    "query_id": row[0],
                    "query_text": row[1],
                    "start_time": str(row[2]),
                    "end_time": str(row[3])
                })

            # 7) Other logs (example: stl_error)
            other_logs = inspect_other_logs(cur, args.target_user)
            db_report["other_logs"] = []
            for row in other_logs:
                db_report["other_logs"].append({
                    "userid": row[0],
                    "recordtime": str(row[1]),
                    "errcode": row[2],
                    "sequence": row[3],
                    "filename": row[4],
                    "session_id": row[5],
                    "line_number": row[6],
                    "err_reason": row[7],
                })

        conn.close()

        # Store the database-specific report
        data_report[conn_params["database"]] = db_report


    # Identify potential blockers for DROP USER
    # This is separate logic that you can define as "dropping blockers"
    # e.g. if there are owned_objects, active_sessions, stored_procedures, group memberships
    dropping_blockers = []
    for db, db_data in data_report.items():
        if len(db_data["owned_objects"]) > 0:
            dropping_blockers.append(f"User owns database objects in '{db}'; reassign or drop them first.")
        if len(db_data["active_sessions"]) > 0:
            dropping_blockers.append(f"User has active sessions in '{db}'; terminate them first.")
        if len(db_data["stored_procedures"]) > 0:
            dropping_blockers.append(f"User owns stored procedures in '{db}'; reassign or drop them first.")
        if len(db_data["group_memberships"]) > 0:
            dropping_blockers.append(f"User is a member of some group(s) in '{db}'; remove from those groups first.")

    data_report["dropping_blockers"] = dropping_blockers

    # Print to console
    print("=== Potential Drop-User Blockers ===")
    if dropping_blockers:
        for block in dropping_blockers:
            print(f" - {block}")
    else:
        sys.stderr.write("No immediate blockers found. (Still double-check permissions & references.)")

    summary_write_to = sys.stdout
    if args.json_out:
        # Write the entire data_report to JSON
        file = args.json_out
        # If file is "-" write to stdout
        if file == "-":
            print(json.dumps(data_report, indent=2, default=str))
        else:
            with open(args.json_out, "w", encoding="utf-8") as f:
                json.dump(data_report, f, indent=2, default=str)
        sys.stderr.write(f"\nDetailed report written to '{args.json_out}'\n")
        summary_write_to = sys.stderr

    # Either way, write a summary to the console
    summary_write_to.write("\n=== Summary of Collected Data (console preview) ===\n")
    for db, report in data_report.items():
        if db == "dropping_blockers":
            continue

        # If error, the report will be empty, so skip it
        if not report:
            continue

        summary_write_to.write(f"\nDatabase: {db}\n")
        for k, v in report.items():
            summary_write_to.write(f"- {k}: {len(v)} record(s)\n")

if __name__ == "__main__":
    main()