#!/usr/bin/env python3

import sys
import boto3
from io import BytesIO
import zipfile
import os
import argparse
import fnmatch

def expand_glob_patterns(s3, bucket_name, object_keys):
    """Expand glob patterns in object keys to actual S3 object keys"""
    expanded_keys = []
    
    for key in object_keys:
        if '*' in key or '?' in key:
            # This is a glob pattern, need to expand it
            print(f"Expanding glob pattern: {key}")
            
            # Extract prefix for more efficient listing
            prefix = key.split('*')[0].split('?')[0]
            if not prefix:
                prefix = ""
            
            # List objects with the prefix
            paginator = s3.get_paginator('list_objects_v2')
            page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)
            
            matching_keys = []
            for page in page_iterator:
                if 'Contents' in page:
                    for obj in page['Contents']:
                        obj_key = obj['Key']
                        if fnmatch.fnmatch(obj_key, key):
                            matching_keys.append(obj_key)
            
            if matching_keys:
                expanded_keys.extend(matching_keys)
                print(f"  Found {len(matching_keys)} matching objects")
            else:
                print(f"  No objects found matching pattern: {key}")
        else:
            # No glob pattern, use as-is
            expanded_keys.append(key)
    
    return expanded_keys

def download_files_to_zip(output_zip_name, profile_name, region, bucket_name, *object_keys):
    # Initialize a session using AWS profile
    session = boto3.Session(profile_name=profile_name, region_name=region)
    s3 = session.client('s3')
    
    # Expand any glob patterns in the object keys
    expanded_keys = expand_glob_patterns(s3, bucket_name, object_keys)
    
    # If we expanded any patterns, show confirmation
    if len(expanded_keys) != len(object_keys):
        print(f"\nExpanded {len(object_keys)} input patterns to {len(expanded_keys)} objects:")
        for key in expanded_keys:
            print(f"  {key}")
        
        response = input(f"\nDownload {len(expanded_keys)} objects? (y/N): ")
        if response.lower() != 'y':
            print("Download cancelled.")
            return
    
    # Create ZIP file directly on disk, not in memory
    with zipfile.ZipFile(output_zip_name, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for i, object_key in enumerate(expanded_keys, 1):
            # Retrieve the object from S3
            print(f"Downloading {object_key} from {bucket_name} ({i}/{len(expanded_keys)})")
            
            # Stream the file directly to the ZIP without loading into memory
            s3_response = s3.get_object(Bucket=bucket_name, Key=object_key)
            
            # Use writestr with the streaming response body
            zip_file.writestr(object_key, s3_response['Body'].read())
            
            # Force write to disk periodically to avoid memory buildup
            if i % 100 == 0:
                zip_file.fp.flush()
                print(f"  Progress: {i}/{len(expanded_keys)} files processed")
    
    print(f"\nZIP file created: {output_zip_name}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='''S3 file batch download and ZIP creation tool.

This tool downloads multiple files from an S3 bucket and packages them into a single ZIP file. 
It's designed for batch operations where you need to retrieve multiple objects and combine them 
into a compressed archive for easier handling or distribution.

Key use cases:
- Batch downloads: Download multiple S3 objects in a single operation
- Data packaging: Create ZIP archives of related S3 files
- Backup operations: Package multiple files for backup or transfer
- Distribution: Bundle files for sharing or deployment
- Data processing: Prepare file collections for analysis or processing
- Pattern matching: Use glob patterns (* and ?) to download multiple files matching a pattern

The tool downloads each specified S3 object and adds it to a ZIP file with the original key 
structure preserved. It supports glob patterns for bulk operations and provides progress feedback 
during downloads. When glob patterns are used, it will show a confirmation prompt before downloading 
the expanded list of objects.''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('output_zip_name', help='Output ZIP file name')
    parser.add_argument('profile_name', help='AWS profile name')
    parser.add_argument('region', help='AWS region')
    parser.add_argument('bucket_name', help='S3 bucket name')
    parser.add_argument('object_keys', nargs='+', help='S3 object keys to download (supports glob patterns with * and ?)')
    args = parser.parse_args()
    
    output_zip_name = args.output_zip_name
    profile_name = args.profile_name
    region = args.region
    bucket_name = args.bucket_name
    object_keys = args.object_keys

    # Set AWS profile and region environment variables
    os.environ['AWS_PROFILE'] = profile_name
    os.environ['AWS_DEFAULT_REGION'] = region
    
    download_files_to_zip(output_zip_name, profile_name, region, bucket_name, *object_keys)
